{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully retrieved from server.\n",
      "\n",
      "First 5 rows of data:\n",
      "  status message                                               json\n",
      "0    200      ok  {\"index\":{\"0\":0,\"1\":1,\"2\":2,\"3\":3,\"4\":4,\"5\":5,...\n",
      "\n",
      "Data saved as 'dataset.csv'.\n",
      "\n",
      "No complex columns found. No unpacking needed.\n",
      "\n",
      "Data is prepared and ready for further processing.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"parser_errors.log\",\n",
    "    level=logging.ERROR,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Load configuration\n",
    "try:\n",
    "    with open(\"config.json\", \"r\", encoding=\"utf-8\") as config_file:\n",
    "        config = json.load(config_file)\n",
    "        url = config.get(\"url\")\n",
    "        token = config.get(\"token\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading configuration: {e}\")\n",
    "    print(\"Error loading 'config.json'.\")\n",
    "    exit()\n",
    "\n",
    "# HTTP headers\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\"\n",
    "}\n",
    "\n",
    "# Fetch data from server\n",
    "try:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    print(\"Data successfully retrieved from server.\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    logging.error(f\"HTTP request error: {e}\")\n",
    "    print(\"Error retrieving data.\")\n",
    "    exit()\n",
    "\n",
    "# Parse JSON content directly from memory\n",
    "try:\n",
    "    data = response.json()\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error parsing JSON response: {e}\")\n",
    "    print(\"Error parsing JSON response.\")\n",
    "    exit()\n",
    "\n",
    "# Convert to DataFrame\n",
    "try:\n",
    "    if isinstance(data, list):\n",
    "        df = pd.DataFrame(data)\n",
    "    elif isinstance(data, dict):\n",
    "        df = pd.json_normalize(data)\n",
    "    else:\n",
    "        raise Exception(\"Unsupported data format.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error converting to DataFrame: {e}\")\n",
    "    print(\"Unsupported data format.\")\n",
    "    exit()\n",
    "\n",
    "# Display first 5 rows\n",
    "print(\"\\nFirst 5 rows of data:\")\n",
    "print(df.head(5))\n",
    "\n",
    "# Save to CSV\n",
    "try:\n",
    "    df.to_csv(\"dataset.csv\", index=False, encoding=\"utf-8\")\n",
    "    print(\"\\nData saved as 'dataset.csv'.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error saving CSV file: {e}\")\n",
    "    print(\"Error saving CSV file.\")\n",
    "\n",
    "# Identify complex columns\n",
    "def is_complex_type(elem):\n",
    "    return isinstance(elem, (dict, list))\n",
    "\n",
    "def is_list(elem):\n",
    "    return isinstance(elem, list)\n",
    "\n",
    "try:\n",
    "    complex_columns = [col for col in df.columns if df[col].map(is_complex_type).any()]\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error identifying complex columns: {e}\")\n",
    "    complex_columns = []\n",
    "\n",
    "# Unpack complex columns\n",
    "if complex_columns:\n",
    "    print(\"\\nFound complex columns:\", complex_columns)\n",
    "\n",
    "    for col in complex_columns:\n",
    "        try:\n",
    "            print(f\"\\nUnpacking column: {col}\")\n",
    "            col_non_null = df[col].dropna()\n",
    "            if col_non_null.map(is_list).all():\n",
    "                # Explode if all values are lists\n",
    "                exploded = df[[col]].explode(col)\n",
    "                nested_df = pd.json_normalize(exploded[col])\n",
    "            else:\n",
    "                # Otherwise assume dicts\n",
    "                nested_df = pd.json_normalize(col_non_null)\n",
    "\n",
    "            nested_df.to_csv(f\"{col}_table.csv\", index=False, encoding=\"utf-8\")\n",
    "            print(f\"Column '{col}' unpacked and saved as '{col}_table.csv'.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing column '{col}': {e}\")\n",
    "            print(f\"Error processing column: '{col}'. See 'parser_errors.log'.\")\n",
    "else:\n",
    "    print(\"\\nNo complex columns found. No unpacking needed.\")\n",
    "\n",
    "print(\"\\nData is prepared and ready for further processing.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

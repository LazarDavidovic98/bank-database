{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully retrieved from server.\n",
      "\n",
      "First 5 rows of data:\n",
      "  status message                                               json\n",
      "0    200      ok  {\"index\":{\"0\":0,\"1\":1,\"2\":2,\"3\":3,\"4\":4,\"5\":5,...\n",
      "\n",
      "Data saved as 'dataset.csv'.\n",
      "\n",
      "No complex columns found. No unpacking needed.\n",
      "\n",
      "Data is prepared and ready for further processing.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"parser_errors.log\",\n",
    "    level=logging.ERROR,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Load configuration\n",
    "try:\n",
    "    with open(\"config.json\", \"r\", encoding=\"utf-8\") as config_file:\n",
    "        config = json.load(config_file)\n",
    "        url = config.get(\"url\")\n",
    "        token = config.get(\"token\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading configuration: {e}\")\n",
    "    print(\"Error loading 'config.json'.\")\n",
    "    exit()\n",
    "\n",
    "# HTTP headers\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\"\n",
    "}\n",
    "\n",
    "# Fetch data from server\n",
    "try:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    print(\"Data successfully retrieved from server.\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    logging.error(f\"HTTP request error: {e}\")\n",
    "    print(\"Error retrieving data.\")\n",
    "    exit()\n",
    "\n",
    "# Parse JSON content directly from memory\n",
    "try:\n",
    "    data = response.json()\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error parsing JSON response: {e}\")\n",
    "    print(\"Error parsing JSON response.\")\n",
    "    exit()\n",
    "\n",
    "# Convert to DataFrame\n",
    "try:\n",
    "    if isinstance(data, list):\n",
    "        df = pd.DataFrame(data)\n",
    "    elif isinstance(data, dict):\n",
    "        df = pd.json_normalize(data)\n",
    "    else:\n",
    "        raise Exception(\"Unsupported data format.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error converting to DataFrame: {e}\")\n",
    "    print(\"Unsupported data format.\")\n",
    "    exit()\n",
    "\n",
    "# Display first 5 rows\n",
    "print(\"\\nFirst 5 rows of data:\")\n",
    "print(df.head(5))\n",
    "\n",
    "# Save to CSV\n",
    "try:\n",
    "    df.to_csv(\"dataset.csv\", index=False, encoding=\"utf-8\")\n",
    "    print(\"\\nData saved as 'dataset.csv'.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error saving CSV file: {e}\")\n",
    "    print(\"Error saving CSV file.\")\n",
    "\n",
    "# Identify complex columns\n",
    "def is_complex_type(elem):\n",
    "    return isinstance(elem, (dict, list))\n",
    "\n",
    "def is_list(elem):\n",
    "    return isinstance(elem, list)\n",
    "\n",
    "try:\n",
    "    complex_columns = [col for col in df.columns if df[col].map(is_complex_type).any()]\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error identifying complex columns: {e}\")\n",
    "    complex_columns = []\n",
    "\n",
    "# Unpack complex columns\n",
    "if complex_columns:\n",
    "    print(\"\\nFound complex columns:\", complex_columns)\n",
    "\n",
    "    for col in complex_columns:\n",
    "        try:\n",
    "            print(f\"\\nUnpacking column: {col}\")\n",
    "            col_non_null = df[col].dropna()\n",
    "            if col_non_null.map(is_list).all():\n",
    "                # Explode if all values are lists\n",
    "                exploded = df[[col]].explode(col)\n",
    "                nested_df = pd.json_normalize(exploded[col])\n",
    "            else:\n",
    "                # Otherwise assume dicts\n",
    "                nested_df = pd.json_normalize(col_non_null)\n",
    "\n",
    "            nested_df.to_csv(f\"{col}_table.csv\", index=False, encoding=\"utf-8\")\n",
    "            print(f\"Column '{col}' unpacked and saved as '{col}_table.csv'.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing column '{col}': {e}\")\n",
    "            print(f\"Error processing column: '{col}'. See 'parser_errors.log'.\")\n",
    "else:\n",
    "    print(\"\\nNo complex columns found. No unpacking needed.\")\n",
    "\n",
    "print(\"\\nData is prepared and ready for further processing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the database!\n",
      "Column names in CSV file: ['status', 'message', 'json']\n",
      "Detected JSON in column 'json', unpacking...\n",
      "Data after unpacking:\n",
      "   index                   City       Date  Card Type Exp Type Gender  Amount\n",
      "0      0           Delhi, India  29-Oct-14       Gold    Bills      F   82475\n",
      "1      1  Greater Mumbai, India  22-Aug-14   Platinum    Bills      F   32555\n",
      "2      2       Bengaluru, India  27-Aug-14     Silver    Bills      F  101738\n",
      "3      3  Greater Mumbai, India  12-Apr-14  Signature    Bills      F  123424\n",
      "4      4       Bengaluru, India   5-May-15       Gold    Bills      F  171574\n",
      "Normalized column names: ['index', 'city', 'date', 'card type', 'exp type', 'gender', 'amount']\n",
      "First 5 cleaned rows:\n",
      "   index                   city       date  card type exp type gender  amount\n",
      "0      0           Delhi, India  29-Oct-14       Gold    Bills      F   82475\n",
      "1      1  Greater Mumbai, India  22-Aug-14   Platinum    Bills      F   32555\n",
      "2      2       Bengaluru, India  27-Aug-14     Silver    Bills      F  101738\n",
      "3      3  Greater Mumbai, India  12-Apr-14  Signature    Bills      F  123424\n",
      "4      4       Bengaluru, India   5-May-15       Gold    Bills      F  171574\n",
      "Table 'transactions' has been cleared using TRUNCATE.\n",
      "Data successfully inserted into 'transactions'.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "server = \"localhost\\\\MSSQLSERVER01\"\n",
    "database = \"banka\"\n",
    "conn_str = f'DRIVER={{SQL Server}};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "\n",
    "try:\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Successfully connected to the database!\")\n",
    "\n",
    "    # Ensure the table exists, otherwise create it\n",
    "    create_table_query = \"\"\"\n",
    "    IF OBJECT_ID('dbo.transactions', 'U') IS NULL\n",
    "    CREATE TABLE transactions (\n",
    "        id INT IDENTITY(1,1) PRIMARY KEY,\n",
    "        city NVARCHAR(255),\n",
    "        date DATE,\n",
    "        card_type NVARCHAR(50),\n",
    "        exp_type NVARCHAR(50),\n",
    "        gender CHAR(1),\n",
    "        amount INT\n",
    "    )\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit()\n",
    "\n",
    "    # Truncate the table to remove old data\n",
    "    cursor.execute(\"TRUNCATE TABLE dbo.transactions;\")\n",
    "    conn.commit()\n",
    "    print(\"Table 'transactions' has been cleared.\")\n",
    "\n",
    "    # Prepare insert query\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO transactions (city, date, card_type, exp_type, gender, amount)\n",
    "    VALUES (?, ?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "\n",
    "    # Read CSV in chunks\n",
    "    chunks = pd.read_csv(\"dataset.csv\", sep=\",\", encoding=\"utf-8-sig\", chunksize=1000)\n",
    "\n",
    "    for chunk in chunks:\n",
    "        # Optional JSON unpacking (if needed)\n",
    "        if \"json\" in chunk.columns:\n",
    "            print(\"Detected JSON in 'json' column. Unpacking first row only for simplicity.\")\n",
    "            unpacked = json.loads(chunk[\"json\"].iloc[0])\n",
    "            chunk = pd.DataFrame(unpacked)\n",
    "\n",
    "        # Normalize column names\n",
    "        chunk.columns = chunk.columns.str.strip().str.lower()\n",
    "\n",
    "        # Rename city column if necessary\n",
    "        if \"city\" not in chunk.columns:\n",
    "            for col in chunk.columns:\n",
    "                if \"city\" in col.lower():\n",
    "                    chunk.rename(columns={col: \"city\"}, inplace=True)\n",
    "                    break\n",
    "\n",
    "        # Convert data types\n",
    "        chunk[\"date\"] = chunk[\"date\"].astype(str)\n",
    "        chunk[\"amount\"] = chunk[\"amount\"].astype(int)\n",
    "\n",
    "        # Prepare values directly from chunk (generator)\n",
    "        values = zip(\n",
    "            chunk[\"city\"],\n",
    "            chunk[\"date\"],\n",
    "            chunk[\"card type\"],\n",
    "            chunk[\"exp type\"],\n",
    "            chunk[\"gender\"],\n",
    "            chunk[\"amount\"]\n",
    "        )\n",
    "\n",
    "        cursor.executemany(insert_query, list(values))  # or just values if pyodbc supports it\n",
    "        conn.commit()\n",
    "        print(\"Inserted 1000 rows...\")\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"All data inserted successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Database connection error:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
